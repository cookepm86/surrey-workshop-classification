{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "Want to explore data before model building.\n",
    "In particular:\n",
    "* Check data quality\n",
    "* Understand feature/target distributions\n",
    "* Identify import features by correlation\n",
    "* Understand correlations between features\n",
    "\n",
    "**Equivalent:** if we had to build a logistic regression model with a small number of features, how would I build this model?\n",
    "Check out https://www.statlearning.com/ for a great introduction to logistic regression and Random Forest model\n",
    "which we will use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import poisson, probplot\n",
    "from seaborn import boxplot, heatmap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from kindred_cmap import double as kindred_cmap\n",
    "\n",
    "pd.set_option(\"max_columns\", 100)\n",
    "plt.style.use(\"/Users/miccoo/Desktop/kindred.mplstyle\")\n",
    "kcs = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Taken from https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=\"legend.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../data/default of credit card clients.xls\", header=1, index_col=0)\n",
    "print(f\"The client IDs are unique: {df.index.is_unique}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality\n",
    "\n",
    "Looks good initially, we don't have any nulls and all categorical features are encoded as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions to the stakeholders:\n",
    "* Do we have a benchmark? **TODO:** move to other NB\n",
    "* Is there any additional data they think might be useful?\n",
    "* Is any of the data known to be unreliable?\n",
    "* Can they explain any fields which we're not sure of the meaning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Preprocessing\n",
    "\n",
    "Columns names with whitespace are a pain, and it looks like the 0 subscript for PAY is misleading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(\n",
    "    columns={\n",
    "        \"default payment next month\": \"DEFAULT\",\n",
    "        \"PAY_0\": \"PAY_1\"\n",
    "    }, \n",
    "    inplace=True\n",
    ")\n",
    "df[\"SEX\"] -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target\n",
    "\n",
    "The target distribution is quite **imbalanced**. \n",
    "This will inform metric and model choice - \n",
    "in particular, are false positives (FPs) more important than false negatives (FNs) or vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_val_counts = df[\"DEFAULT\"].value_counts(normalize=True)\n",
    "print(f\"{round(100*churn_val_counts.loc[1], 2)}% of clients default.\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(churn_val_counts.index, churn_val_counts.values)\n",
    "ax.set(\n",
    "    title=\"Default Distribution\", xlabel=\"Default\", ylabel=\"Fraction\", \n",
    "    xticks=[0, 1], xticklabels=[\"False\", \"True\"]\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a glimpse of correlations.\n",
    "We choose a Spearman correlation with the Random Forest in mind,\n",
    "where only ordering of features matters.\n",
    "\n",
    "The *PAY_N* features are the most correlated with the target, \n",
    "which is not surprising.\n",
    "*LIMIT_BAL* is anti-correlated with the target variable, \n",
    "as are *PAY_AMTN*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = df.corr(\"spearman\")\n",
    "\n",
    "corr_df[\"DEFAULT\"].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 2 sexes - mostly female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_dict = {0: \"male\", 1: \"female\"}\n",
    "\n",
    "sex_val_counts = df[\"SEX\"].value_counts(normalize=True)\n",
    "print(f\"{round(100*sex_val_counts.loc[1], 2)}% of clients are female.\")\n",
    "\n",
    "sex_default_matrix = \\\n",
    "    df\\\n",
    "    .groupby([\"SEX\", \"DEFAULT\"])\\\n",
    "    [\"LIMIT_BAL\"]\\\n",
    "    .count()\\\n",
    "    .rename(\"COUNT\")\\\n",
    "    .reset_index()\\\n",
    "    .pivot_table(values=\"COUNT\", index=[\"SEX\"], columns=[\"DEFAULT\"])\n",
    "# normalize by counts\n",
    "sex_default_matrix /= sex_default_matrix.sum(axis=1).values.reshape(-1, 1)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "ax1.bar(sex_val_counts.index, sex_val_counts.values)\n",
    "ax1.set(\n",
    "    title=\"Sex Distribution\", xlabel=\"Sex\", ylabel=\"Fraction\", \n",
    "    xticks=[0, 1], xticklabels=[\"Male\", \"Female\"]\n",
    ")\n",
    "\n",
    "heatmap(\n",
    "    sex_default_matrix[[1]], \n",
    "    linewidth=5, \n",
    "    annot=True, \n",
    "    annot_kws={\"size\": 24}, \n",
    "    cmap=kindred_cmap\n",
    ")\n",
    "ax2.set(\n",
    "    title=\"Default Rate by Sex\", xlabel=\"Default Rate\", ylabel=\"Sex\", \n",
    "    xticks=[0.5], xticklabels=[],\n",
    "    yticks=[0.5, 1.5], yticklabels=[\"Male\", \"Female\"]\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no particularly strong correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df[\"SEX\"].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Education\n",
    "\n",
    "Most customers have university or graduate school education.\n",
    "Some unknown categories - these could be lumped together.\n",
    "There are also values 0 (only 14) which are undefined by the legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the legend\n",
    "education_dict = {\n",
    "    0: \"Missing\",\n",
    "    1: \"Graduate School\", \n",
    "    2: \"University\", \n",
    "    3: \"High School\",\n",
    "    4: \"Others\",\n",
    "    5: \"Unknown\",\n",
    "    6: \"Unknown\"\n",
    "}\n",
    "\n",
    "education_val_counts = df[\"EDUCATION\"].value_counts(normalize=True)\n",
    "for n in range(7):\n",
    "    print(f\"{round(100*education_val_counts.loc[n], 2)}% of clients have {education_dict[n]} education.\")\n",
    "    \n",
    "education_default_matrix = \\\n",
    "    df\\\n",
    "    .groupby([\"EDUCATION\", \"DEFAULT\"])\\\n",
    "    [\"LIMIT_BAL\"]\\\n",
    "    .count()\\\n",
    "    .rename(\"COUNT\")\\\n",
    "    .reset_index()\\\n",
    "    .pivot_table(values=\"COUNT\", index=[\"EDUCATION\"], columns=[\"DEFAULT\"])\\\n",
    "    .fillna(0)\n",
    "education_default_matrix /= education_default_matrix.sum(axis=1).values.reshape(-1, 1)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "ax1.bar(education_val_counts.index, education_val_counts.values)\n",
    "ax1.set(\n",
    "    title=\"Education Distribution\", xlabel=\"Education\", ylabel=\"Fraction\",\n",
    "    xticks=range(7), xticklabels=[education_dict[n] for n in range(7)]\n",
    ")\n",
    "\n",
    "heatmap(\n",
    "    education_default_matrix[[1]], \n",
    "    linewidth=5, \n",
    "    vmin=0.0, \n",
    "    vmax=0.25, \n",
    "    annot=True, \n",
    "    annot_kws={\"size\": 24},\n",
    "    cmap=kindred_cmap\n",
    ")\n",
    "ax2.set(\n",
    "    title=\"Default Rate by Education\", xlabel=\"Default Rate\", ylabel=\"Education\", \n",
    "    xticks=[0.5], xticklabels=[],\n",
    "    yticks=[n + 0.5 for n in range(7)]\n",
    ")\n",
    "ax2.set_yticklabels([education_dict[n] for n in range(7)], rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Education is quite correlated with *LIMIT_BAL*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df[\"EDUCATION\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_df = df.groupby(\"EDUCATION\").mean()\n",
    "education_df = (education_df - education_df.min()) / (education_df.max() - education_df.min())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "heatmap(education_df, cmap=kindred_cmap, vmax=1, vmin=0, ax=ax, linewidth=1)\n",
    "ax.set_yticks(np.array(range(7)) + 0.5)\n",
    "ax.set_yticklabels([education_dict[n] for n in range(7)], rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Marriage\n",
    "\n",
    "Slightly more married customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marriage_dict = {\n",
    "    0: \"Missing\",\n",
    "    1: \"Married\", \n",
    "    2: \"Single\", \n",
    "    3: \"Others\"\n",
    "}\n",
    "\n",
    "marriage_val_counts = df[\"MARRIAGE\"].value_counts(normalize=True)\n",
    "for n in range(4):\n",
    "    print(f\"{round(100*marriage_val_counts.loc[n], 2)}% of clients have {marriage_dict[n]} marriage.\")\n",
    "        \n",
    "marriage_default_matrix = \\\n",
    "    df\\\n",
    "    .groupby([\"MARRIAGE\", \"DEFAULT\"])\\\n",
    "    [\"LIMIT_BAL\"]\\\n",
    "    .count()\\\n",
    "    .rename(\"COUNT\")\\\n",
    "    .reset_index()\\\n",
    "    .pivot_table(values=\"COUNT\", index=[\"MARRIAGE\"], columns=[\"DEFAULT\"])\\\n",
    "    .fillna(0)\n",
    "marriage_default_matrix /= marriage_default_matrix.sum(axis=1).values.reshape(-1, 1)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "ax1.bar(marriage_val_counts.index, marriage_val_counts.values)\n",
    "ax1.set(\n",
    "    title=\"Marriage Distribution\", xlabel=\"Marriage\", ylabel=\"Fraction\",\n",
    "    xticks=range(4), xticklabels=[marriage_dict[n] for n in range(4)]\n",
    ")\n",
    "\n",
    "heatmap(\n",
    "    marriage_default_matrix[[1]], \n",
    "    linewidth=5, \n",
    "    vmin=0.0, \n",
    "    vmax=0.3, \n",
    "    annot=True, \n",
    "    annot_kws={\"size\": 24},\n",
    "    cmap=kindred_cmap\n",
    ")\n",
    "ax2.set(\n",
    "    title=\"Default Rate by Marriage\", xlabel=\"Default Rate\", ylabel=\"Marriage\", \n",
    "    xticks=[0.5], xticklabels=[],\n",
    "    yticks=[n + 0.5 for n in range(4)]\n",
    ")\n",
    "ax2.set_yticklabels([marriage_dict[n] for n in range(4)], rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strong correlation with age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df[\"MARRIAGE\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marriage_df = df.groupby(\"MARRIAGE\").mean()\n",
    "marriage_df = (marriage_df - marriage_df.min()) / (marriage_df.max() - marriage_df.min())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 3))\n",
    "heatmap(marriage_df, cmap=kindred_cmap, vmax=1, vmin=0, ax=ax, linewidth=1)\n",
    "ax.set_yticks(np.array(range(4)) + 0.5)\n",
    "ax.set_yticklabels([marriage_dict[n] for n in range(4)], rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repayment Statuses\n",
    "\n",
    "What does the -2 value represent? Typically go to the stakeholders to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_df = \\\n",
    "    pd.concat([df[f\"PAY_{n}\"].value_counts() for n in range(1, 7)], axis=1)\\\n",
    "    .fillna(0)\\\n",
    "    .astype(int)\\\n",
    "    .T\n",
    "pay_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for n in range(1, 7):\n",
    "    ax.plot(df.groupby(f\"PAY_{n}\")[\"DEFAULT\"].mean(), label=f\"PAY_{n}\")\n",
    "ax.set(title=\"Default Rate by Repayment Status\", ylim=[0, 1], xlabel=\"Status\", ylabel=\"Rate\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a strong correlation with *BILL_AMTN* and anti-correlation with *LIMIT_BAL*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 4))\n",
    "heatmap(\n",
    "    corr_df[[f\"PAY_{n}\" for n in range(1, 7)]].T, \n",
    "    vmax=1, \n",
    "    vmin=-1, \n",
    "    cmap=kindred_cmap, \n",
    "    linewidth=1, \n",
    "    ax=ax\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LIMIT_BAL\n",
    "\n",
    "All positive values, which we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"LIMIT_BAL\"] <= 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "fig.suptitle(\"LIMIT_BAL\", size=26)\n",
    "\n",
    "ax1.hist(df[\"LIMIT_BAL\"])\n",
    "ax1.set(title=\"Linear Scale\", xlabel=\"LIMIT_BAL\", ylabel=\"Count\")\n",
    "\n",
    "ax2.hist(np.log(df[\"LIMIT_BAL\"]))\n",
    "ax2.set(title=\"Log Scale\", xlabel=\"Log(LIMIT_BAL)\", ylabel=\"Count\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There don't appear to be outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"LIMIT_BAL\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not quite log-normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "probplot(np.log(df[\"LIMIT_BAL\"]), plot=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df[\"LIMIT_BAL\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "\n",
    "df[\"LIMIT_BAL_Q\"] = pd.qcut(df[\"LIMIT_BAL\"], 10)\n",
    "\n",
    "df.groupby(\"LIMIT_BAL_Q\")[\"DEFAULT\"].mean().plot(ax=ax, marker=\"x\")\n",
    "ax.set(title=\"Default Rate by LIMIT_BAL\", ylabel=\"Rate\")\n",
    "\n",
    "df.drop(\"LIMIT_BAL_Q\", axis=1, inplace=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BILL_AMT\n",
    "\n",
    "We don't appear to have outliers, but we do have negative bill amounts - maybe clients overpaid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[f\"BILL_AMT{n}\" for n in range(1, 7)]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[[f\"BILL_AMT{n}\" for n in range(1, 7)]] < 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[[f\"BILL_AMT{n}\" for n in range(1, 7)]] == 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, figsize=(20, 16))\n",
    "fig.suptitle(\"Non-negative BILL_AMT Distribution\", fontsize=24)\n",
    "\n",
    "ax1.hist(np.log(1 + df[df[\"BILL_AMT1\"] >= 0][\"BILL_AMT1\"]))\n",
    "ax1.set(xlabel=\"Log(1 + BILL_AMT1)\", ylabel=\"Count\")\n",
    "\n",
    "ax2.hist(np.log(1 + df[df[\"BILL_AMT2\"] >= 0][\"BILL_AMT2\"]))\n",
    "ax2.set(xlabel=\"Log(1 + BILL_AMT2)\", ylabel=\"Count\")\n",
    "\n",
    "ax3.hist(np.log(1 + df[df[\"BILL_AMT3\"] >= 0][\"BILL_AMT3\"]))\n",
    "ax3.set(xlabel=\"Log(1 + BILL_AMT3)\", ylabel=\"Count\")\n",
    "\n",
    "ax4.hist(np.log(1 + df[df[\"BILL_AMT4\"] >= 0][\"BILL_AMT4\"]))\n",
    "ax4.set(xlabel=\"Log(1 + BILL_AMT4)\", ylabel=\"Count\")\n",
    "\n",
    "ax5.hist(np.log(1 + df[df[\"BILL_AMT5\"] >= 0][\"BILL_AMT5\"]))\n",
    "ax5.set(xlabel=\"Log(1 + BILL_AMT5)\", ylabel=\"Count\")\n",
    "\n",
    "ax6.hist(np.log(1 + df[df[\"BILL_AMT6\"] >= 0][\"BILL_AMT6\"]))\n",
    "ax6.set(xlabel=\"Log(1 + BILL_AMT6)\", ylabel=\"Count\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, it is clients with mid-range bill amounts which have the highest default rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "\n",
    "for n in range(1, 7):\n",
    "    df[f\"BILL_AMT{n}_Q\"] = pd.qcut(df[f\"BILL_AMT{n}\"], 5, labels=[f\"Q{m}\" for m in range(1, 6)])\n",
    "\n",
    "for m in range(1, 6):\n",
    "    ax.plot(\n",
    "        range(1, 7), \n",
    "        [df[df[f\"BILL_AMT{n}_Q\"] == f\"Q{m}\"][\"DEFAULT\"].mean() for n in range(1, 7)], \n",
    "        marker=\"x\",\n",
    "        label=f\"Q{m}\"\n",
    "    )\n",
    "ax.set(title=\"Default Rate by BILL_AMT Quintile\", xlabel=\"Month\", ylabel=\"Rate\")\n",
    "ax.legend()\n",
    "\n",
    "for n in range(1, 7):\n",
    "    df.drop(f\"BILL_AMT{n}_Q\", axis=1, inplace=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite correlated across time and, maybe surprisingly, not with *LIMIT_BAL*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 4))\n",
    "heatmap(\n",
    "    corr_df[[f\"BILL_AMT{n}\" for n in range(1, 7)]].T, \n",
    "    vmax=1, \n",
    "    vmin=-1, \n",
    "    cmap=kindred_cmap, \n",
    "    linewidth=1, \n",
    "    ax=ax\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PAY_AMT\n",
    "\n",
    "We don't appear to have outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[f\"PAY_AMT{n}\" for n in range(1, 7)]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, figsize=(20, 16))\n",
    "fig.suptitle(\"Non-negative PAY_AMT Distribution\", fontsize=24)\n",
    "\n",
    "ax1.hist(np.log(1 + df[df[\"PAY_AMT1\"] >= 0][\"PAY_AMT1\"]))\n",
    "ax1.set(xlabel=\"Log(1 + PAY_AMT1)\", ylabel=\"Count\")\n",
    "\n",
    "ax2.hist(np.log(1 + df[df[\"PAY_AMT2\"] >= 0][\"PAY_AMT2\"]))\n",
    "ax2.set(xlabel=\"Log(1 + PAY_AMT2)\", ylabel=\"Count\")\n",
    "\n",
    "ax3.hist(np.log(1 + df[df[\"PAY_AMT3\"] >= 0][\"PAY_AMT3\"]))\n",
    "ax3.set(xlabel=\"Log(1 + PAY_AMT3)\", ylabel=\"Count\")\n",
    "\n",
    "ax4.hist(np.log(1 + df[df[\"PAY_AMT4\"] >= 0][\"PAY_AMT4\"]))\n",
    "ax4.set(xlabel=\"Log(1 + PAY_AMT4)\", ylabel=\"Count\")\n",
    "\n",
    "ax5.hist(np.log(1 + df[df[\"PAY_AMT5\"] >= 0][\"PAY_AMT5\"]))\n",
    "ax5.set(xlabel=\"Log(1 + PAY_AMT5)\", ylabel=\"Count\")\n",
    "\n",
    "ax6.hist(np.log(1 + df[df[\"PAY_AMT6\"] >= 0][\"PAY_AMT6\"]))\n",
    "ax6.set(xlabel=\"Log(1 + PAY_AMT6)\", ylabel=\"Count\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, it is clients with mid-range bill amounts which have the highest default rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "\n",
    "for n in range(1, 7):\n",
    "    df[f\"PAY_AMT{n}_Q\"] = pd.qcut(df[f\"PAY_AMT{n}\"], 3, labels=[f\"Q{m}\" for m in range(1, 4)])\n",
    "\n",
    "for m in range(1, 4):\n",
    "    ax.plot(\n",
    "        range(1, 7), \n",
    "        [df[df[f\"PAY_AMT{n}_Q\"] == f\"Q{m}\"][\"DEFAULT\"].mean() for n in range(1, 7)], \n",
    "        marker=\"x\",\n",
    "        label=f\"Q{m}\"\n",
    "    )\n",
    "ax.set(title=\"Default Rate by PAY_AMT Tercile\", xlabel=\"Month\", ylabel=\"Rate\")\n",
    "ax.legend()\n",
    "\n",
    "for n in range(1, 7):\n",
    "    df.drop(f\"PAY_AMT{n}_Q\", axis=1, inplace=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 4))\n",
    "heatmap(\n",
    "    corr_df[[f\"PAY_AMT{n}\" for n in range(1, 7)]].T, \n",
    "    vmax=1, \n",
    "    vmin=-1, \n",
    "    cmap=kindred_cmap, \n",
    "    linewidth=1, \n",
    "    ax=ax\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems that *PAY_AMTN* lags *BILL_AMTN* by 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.loc[[f\"BILL_AMT{n}\" for n in range(1, 7)], [f\"PAY_AMT{n}\" for n in range(1, 7)]].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we reverse engineer PAY_N?\n",
    "\n",
    "I just had a play around with the max_depth here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop([\"DEFAULT\"] + [f\"PAY_{n}\" for n in range(1, 7)], axis=1).values, df[\"PAY_1\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "dc = DecisionTreeClassifier(random_state=SEED, max_depth=7)\n",
    "dc.fit(X_train, y_train)\n",
    "\n",
    "np.mean(dc.predict(X_train) == y_train), np.mean(dc.predict(X_test) == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalising\n",
    "\n",
    "There is some correlation between *PAY_AMTN*, *BILL_AMTN* and *LIMIT_BAL*.\n",
    "Maybe we can normalize to engineer less correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.loc[\n",
    "    [\"LIMIT_BAL\"] + [f\"BILL_AMT{n}\" for n in range(1, 7)], \n",
    "    [\"LIMIT_BAL\"] + [f\"PAY_AMT{n}\" for n in range(1, 7)]\n",
    "].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1, 7):\n",
    "    df[f\"BILL_AMT_NORM{n}\"] = df[f\"BILL_AMT{n}\"] / df[\"LIMIT_BAL\"]\n",
    "for n in range(1, 6):\n",
    "    df[f\"PAY_AMT_NORM{n}\"] = (0.01 + df[f\"PAY_AMT{n}\"]) / (0.01 + df[f\"BILL_AMT{n+1}\"])\n",
    "    df[f\"LAST_PAY_DIFF{n}\"] = df[f\"BILL_AMT{n+1}\"] - df[f\"PAY_AMT{n}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corr_df = df.corr(\"spearman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This actually looks worse for *BILL_AMT_NORMN*, but better for *PAY_AMTN*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corr_df.loc[\n",
    "    [\"LIMIT_BAL\"] + [f\"BILL_AMT_NORM{n}\" for n in range(1, 7)], \n",
    "    [\"LIMIT_BAL\"] + [f\"PAY_AMT_NORM{n}\" for n in range(1, 6)]\n",
    "].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corr_df[\"DEFAULT\"].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Target is imbalanced - choose appropriate metric/model.\n",
    "* Some of the categorical features have missing data.\n",
    "* Previous repayment statuses are the most correlated features with the target,\n",
    "but the meaning of the statuses is unclear. \n",
    "We can't re-engineer them.\n",
    "* The amount of credit is anti-correlated with the target\n",
    "* Due to correlation between *PAY_AMTN* AND *BILL_AMTN* it may be worth normalizing *PAY_AMTN* by *BILL_AMTN*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surrey-workshop",
   "language": "python",
   "name": "surrey-workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
