{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model\n",
    "\n",
    "Very robust and successful non-parametric machine-learning model https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf\n",
    "Very few assumptions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "from seaborn import boxplot\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "\n",
    "pd.set_option(\"max_columns\", 100)\n",
    "plt.style.use(\"/Users/miccoo/Desktop/kindred.mplstyle\")\n",
    "kcs = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../data/default of credit card clients.xls\", header=1, index_col=0)\n",
    "print(df.index.is_unique)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(\n",
    "    columns={\n",
    "        \"default payment next month\": \"DEFAULT\",\n",
    "        \"PAY_0\": \"PAY_1\"\n",
    "    }, \n",
    "    inplace=True\n",
    ")\n",
    "df[\"SEX\"] -= 1\n",
    "df[\"LOG_LIMIT_BAL\"] = np.log(df[\"LIMIT_BAL\"])\n",
    "for n in range(1, 7):\n",
    "    df[f\"BILL_AMT_NORM{n}\"] = df[f\"BILL_AMT{n}\"] / df[\"LIMIT_BAL\"]\n",
    "for n in range(1, 6):\n",
    "    df[f\"PAY_AMT_NORM{n}\"] = (0.01 + df[f\"PAY_AMT{n}\"]) / (0.01 + df[f\"BILL_AMT{n+1}\"])\n",
    "    df[f\"LAST_PAY_DIFF{n}\"] = df[f\"BILL_AMT{n+1}\"] - df[f\"PAY_AMT{n}\"]\n",
    "df[\"PAY_AMT_NORM6\"] = df[\"PAY_AMT6\"] / df[\"LIMIT_BAL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df, df[\"DEFAULT\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipeline\n",
    "\n",
    "Let's build a simple pipeline which uses a Random Forest model to predict *DEFAULT*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Select columns from pandas dataframe by specifying a list of column names\n",
    "    \"\"\"\n",
    "    def __init__(self, attribute_names=None):\n",
    "        self.attribute_names = attribute_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.loc[:, self.attribute_names]\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return self.attribute_names\n",
    "    \n",
    "    \n",
    "def create_random_forest_pipeline(X_train, \n",
    "                                  y_train,\n",
    "                                  param_grid):\n",
    "    \"\"\"\n",
    "    Create a Random Forest pipeline which\n",
    "    performs basic preprocessing for numerical\n",
    "    and categorical features.\n",
    "\n",
    "    :param X_train: Training feature data\n",
    "    :param y_train: Training target data\n",
    "    :param param_grid: Hyperparameter grid to search over\n",
    "    \"\"\"\n",
    "    # build numerical feature pipeline\n",
    "    num_feature_selector = DataFrameSelector()\n",
    "    num_pipeline = Pipeline([(\"feature_selector\", num_feature_selector)])\n",
    "    \n",
    "    # build categorical feature pipeline\n",
    "    cat_feature_selector = DataFrameSelector()\n",
    "    cat_one_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\")\n",
    "    cat_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"feature_selector\", cat_feature_selector),\n",
    "            (\"one_hot_encoder\", cat_one_hot_encoder)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # combine preprocessing pipelines\n",
    "    union_pipeline = FeatureUnion(\n",
    "        [\n",
    "            (\"num_pipeline\", num_pipeline),\n",
    "            (\"cat_pipeline\", cat_pipeline)\n",
    "        ],\n",
    "        n_jobs=1,\n",
    "        transformer_weights=None\n",
    "    )\n",
    "    \n",
    "    # combine preprocessing with logistic regression model\n",
    "    clf = Pipeline(\n",
    "        steps=[\n",
    "            (\"union\", union_pipeline),\n",
    "            (\"classifier\", RandomForestClassifier(random_state=SEED, n_jobs=1))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # perform hyperparameter tuning via cross-validation\n",
    "    gs = GridSearchCV(\n",
    "        estimator=clf,\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"roc_auc\",\n",
    "        n_jobs=5,\n",
    "        cv=5\n",
    "    )\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    return gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "We don't have many features, so we can do a fair bit by hand.\n",
    "We start with the most important/correlated features, as identified in the EDA notebooks\n",
    "and we incrementally add features in order of (anti-)correlation.\n",
    "\n",
    "We try *BILL_AMTN* AND *BILL_AMT_NORMN* as features to add."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"union__num_pipeline__feature_selector__attribute_names\": [\n",
    "        [\"LIMIT_BAL\"], \n",
    "        [\"LIMIT_BAL\"] + [f\"PAY_AMT{n}\" for n in range(1, 7)],\n",
    "        [\"LIMIT_BAL\"] + [f\"PAY_AMT_NORM{n}\" for n in range(1, 6)],\n",
    "        [\"LIMIT_BAL\"] + [f\"BILL_AMT{n}\" for n in range(1, 7)],\n",
    "        [\"LIMIT_BAL\"] + [f\"BILL_AMT_NORM{n}\" for n in range(1, 7)],\n",
    "    ],\n",
    "    \"union__cat_pipeline__feature_selector__attribute_names\": [\n",
    "        [\"PAY_1\"], \n",
    "        [f\"PAY_{n}\" for n in range(1, 7)],\n",
    "    ],\n",
    "    \"classifier__n_estimators\": [100],\n",
    "    \"classifier__max_depth\": [5, 10],\n",
    "    \"classifier__max_features\": [\"auto\"],\n",
    "    \"classifier__class_weight\": [None]\n",
    "}\n",
    "\n",
    "gs = create_random_forest_pipeline(X_train, y_train, param_grid)\n",
    "validation_auc = gs.best_score_\n",
    "test_auc = roc_auc_score(y_test, gs.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f\"Validation ROC-AUC score: {round(100*validation_auc, 2)}\")\n",
    "print(f\"Test ROC-AUC score: {round(100*test_auc, 2)}\\n\")\n",
    "pprint(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try adding *PAY_AMTN* OR *PAY_AMT_NORMN*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"union__num_pipeline__feature_selector__attribute_names\": [\n",
    "        [\"LIMIT_BAL\"] + [f\"BILL_AMT_NORM{n}\" for n in range(1, 7)],\n",
    "        [\"LIMIT_BAL\"] + [f\"BILL_AMT_NORM{n}\" for n in range(1, 7)] + [f\"PAY_AMT{n}\" for n in range(1, 6)],\n",
    "        [\"LIMIT_BAL\"] + [f\"BILL_AMT_NORM{n}\" for n in range(1, 7)] + [f\"PAY_AMT_NORM{n}\" for n in range(1, 6)],\n",
    "    ],\n",
    "    \"union__cat_pipeline__feature_selector__attribute_names\": [\n",
    "        [f\"PAY_{n}\" for n in range(1, 7)],\n",
    "    ],\n",
    "    \"classifier__n_estimators\": [100],\n",
    "    \"classifier__max_depth\": [5, 10],\n",
    "    \"classifier__max_features\": [\"auto\"],\n",
    "    \"classifier__class_weight\": [None]\n",
    "}\n",
    "\n",
    "gs = create_random_forest_pipeline(X_train, y_train, param_grid)\n",
    "validation_auc = gs.best_score_\n",
    "test_auc = roc_auc_score(y_test, gs.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f\"Validation ROC-AUC score: {round(100*validation_auc, 2)}\")\n",
    "print(f\"Test ROC-AUC score: {round(100*test_auc, 2)}\\n\")\n",
    "pprint(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try adding *PAY_AMT6* or *PAY_AMT_NORM6*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"union__num_pipeline__feature_selector__attribute_names\": [\n",
    "        [\"LIMIT_BAL\"] \n",
    "        + [f\"BILL_AMT_NORM{n}\" for n in range(1, 7)] \n",
    "        + [f\"PAY_AMT_NORM{n}\" for n in range(1, 6)],\n",
    "        [\"LIMIT_BAL\", \"PAY_AMT6\"] \n",
    "        + [f\"BILL_AMT_NORM{n}\" for n in range(1, 7)] \n",
    "        + [f\"PAY_AMT_NORM{n}\" for n in range(1, 6)],\n",
    "        [\"LIMIT_BAL\", \"PAY_AMT_NORM6\"] \n",
    "        + [f\"BILL_AMT_NORM{n}\" for n in range(1, 7)] \n",
    "        + [f\"PAY_AMT_NORM{n}\" for n in range(1, 6)],\n",
    "    ],\n",
    "    \"union__cat_pipeline__feature_selector__attribute_names\": [\n",
    "        [f\"PAY_{n}\" for n in range(1, 7)],\n",
    "    ],\n",
    "    \"classifier__n_estimators\": [100],\n",
    "    \"classifier__max_depth\": [5, 10],\n",
    "    \"classifier__max_features\": [\"auto\"],\n",
    "    \"classifier__class_weight\": [None]\n",
    "}\n",
    "\n",
    "gs = create_random_forest_pipeline(X_train, y_train, param_grid)\n",
    "validation_auc = gs.best_score_\n",
    "test_auc = roc_auc_score(y_test, gs.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f\"Validation ROC-AUC score: {round(100*validation_auc, 2)}\")\n",
    "print(f\"Test ROC-AUC score: {round(100*test_auc, 2)}\\n\")\n",
    "pprint(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try adding *LAST_DAY_DIFFN*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"union__num_pipeline__feature_selector__attribute_names\": [\n",
    "        [\"LIMIT_BAL\", \"PAY_AMT6\"] \n",
    "        + [f\"BILL_AMT_NORM{n}\" for n in range(1, 7)] \n",
    "        + [f\"PAY_AMT_NORM{n}\" for n in range(1, 6)],\n",
    "        [\"LIMIT_BAL\", \"PAY_AMT6\"] \n",
    "        + [f\"BILL_AMT_NORM{n}\" for n in range(1, 7)] \n",
    "        + list(chain(*[[f\"PAY_AMT_NORM{n}\", f\"LAST_PAY_DIFF{n}\"] for n in range(1, 6)])),\n",
    "    ],\n",
    "    \"union__cat_pipeline__feature_selector__attribute_names\": [\n",
    "        [],\n",
    "        [f\"PAY_{n}\" for n in range(1, 7)],\n",
    "    ],\n",
    "    \"classifier__n_estimators\": [100],\n",
    "    \"classifier__max_depth\": [5, 10],\n",
    "    \"classifier__max_features\": [\"auto\"],\n",
    "    \"classifier__class_weight\": [None]\n",
    "}\n",
    "\n",
    "gs = create_random_forest_pipeline(X_train, y_train, param_grid)\n",
    "validation_auc = gs.best_score_\n",
    "test_auc = roc_auc_score(y_test, gs.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f\"Validation ROC-AUC score: {round(100*validation_auc, 2)}\")\n",
    "print(f\"Test ROC-AUC score: {round(100*test_auc, 2)}\\n\")\n",
    "pprint(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try adding the demographic features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"union__num_pipeline__feature_selector__attribute_names\": [\n",
    "        [\"LIMIT_BAL\", \"PAY_AMT6\"] \n",
    "        + [f\"BILL_AMT_NORM{n}\" for n in range(1, 7)] \n",
    "        + [f\"PAY_AMT_NORM{n}\" for n in range(1, 6)],\n",
    "        [\"LIMIT_BAL\", \"PAY_AMT6\", \"AGE\"] \n",
    "        + [f\"BILL_AMT_NORM{n}\" for n in range(1, 7)] \n",
    "        + [f\"PAY_AMT_NORM{n}\" for n in range(1, 6)],\n",
    "    ],\n",
    "    \"union__cat_pipeline__feature_selector__attribute_names\": [\n",
    "        [f\"PAY_{n}\" for n in range(1, 7)],\n",
    "        [\"EDUCATION\"] + [f\"PAY_{n}\" for n in range(1, 7)],\n",
    "        [\"MARRIAGE\"] + [f\"PAY_{n}\" for n in range(1, 7)],\n",
    "        [\"SEX\"] + [f\"PAY_{n}\" for n in range(1, 7)],\n",
    "        [\"EDUCATION\", \"MARRIAGE\"] + [f\"PAY_{n}\" for n in range(1, 7)],\n",
    "        [\"EDUCATION\", \"SEX\"] + [f\"PAY_{n}\" for n in range(1, 7)],\n",
    "        [\"MARRIAGE\", \"SEX\"] + [f\"PAY_{n}\" for n in range(1, 7)],\n",
    "        [\"EDUCATION\", \"MARRIAGE\", \"SEX\"] + [f\"PAY_{n}\" for n in range(1, 7)],\n",
    "    ],\n",
    "    \"classifier__n_estimators\": [100],\n",
    "    \"classifier__max_depth\": [5, 10],\n",
    "    \"classifier__max_features\": [\"auto\"],\n",
    "    \"classifier__class_weight\": [None]\n",
    "}\n",
    "\n",
    "gs = create_random_forest_pipeline(X_train, y_train, param_grid)\n",
    "validation_auc = gs.best_score_\n",
    "test_auc = roc_auc_score(y_test, gs.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f\"Validation ROC-AUC score: {round(100*validation_auc, 2)}\")\n",
    "print(f\"Test ROC-AUC score: {round(100*test_auc, 2)}\\n\")\n",
    "pprint(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine the most important features in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model coefficients\n",
    "feature_importance_df = \\\n",
    "    pd.DataFrame(\n",
    "    zip(\n",
    "        gs.best_estimator_[\"union\"].transformer_list[0][1][\"feature_selector\"].get_feature_names()\n",
    "        + gs.best_estimator_[\"union\"].transformer_list[1][1][\"one_hot_encoder\"].get_feature_names_out().tolist(),\n",
    "        100*gs.best_estimator_[\"classifier\"].feature_importances_\n",
    "    ),\n",
    "    columns=[\"feature\", \"coef_\"])\\\n",
    "    .set_index(\"feature\")\\\n",
    "    .sort_values(\"coef_\", ascending=False)\n",
    "\n",
    "feature_importance_df\\\n",
    "    .head(10)\\\n",
    "    .round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the least important!\n",
    "We could look at removing some of the least important features, \n",
    "or rolling them into another feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df\\\n",
    "    .tail(10)\\\n",
    "    .round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Now that we have performed feature selection \n",
    "(with close to the default hyperparameters for Random Forest),\n",
    "we will tune the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"union__num_pipeline__feature_selector__attribute_names\": [\n",
    "        [\"LIMIT_BAL\", \"PAY_AMT6\", \"AGE\"] \n",
    "        + [f\"BILL_AMT_NORM{n}\" for n in range(1, 7)] \n",
    "        + [f\"PAY_AMT_NORM{n}\" for n in range(1, 6)],\n",
    "    ],\n",
    "    \"union__cat_pipeline__feature_selector__attribute_names\": [\n",
    "        [\"EDUCATION\", \"MARRIAGE\"] + [f\"PAY_{n}\" for n in range(1, 7)],\n",
    "    ],\n",
    "    \"classifier__n_estimators\": [50, 100, 150, 200, 250],\n",
    "    \"classifier__max_depth\": [5, 10, 15],\n",
    "    \"classifier__max_features\": [3, \"auto\"],\n",
    "    \"classifier__class_weight\": [\n",
    "        None, \n",
    "        {0: 1, 1: 1.5},\n",
    "        {0: 1, 1: 2},\n",
    "        {0: 1, 1: 2.5},\n",
    "        {0: 1, 1: 3},\n",
    "        \"balanced\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "gs = create_random_forest_pipeline(X_train, y_train, param_grid)\n",
    "validation_auc = gs.best_score_\n",
    "test_auc = roc_auc_score(y_test, gs.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f\"Validation ROC-AUC score: {round(100*validation_auc, 2)}\")\n",
    "print(f\"Test ROC-AUC score: {round(100*test_auc, 2)}\\n\")\n",
    "pprint(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model coefficients\n",
    "feature_importance_df = \\\n",
    "    pd.DataFrame(\n",
    "    zip(\n",
    "        gs.best_estimator_[\"union\"].transformer_list[0][1][\"feature_selector\"].get_feature_names()\n",
    "        + gs.best_estimator_[\"union\"].transformer_list[1][1][\"one_hot_encoder\"].get_feature_names_out().tolist(),\n",
    "        100*gs.best_estimator_[\"classifier\"].feature_importances_\n",
    "    ),\n",
    "    columns=[\"feature\", \"coef_\"])\\\n",
    "    .set_index(\"feature\")\\\n",
    "    .sort_values(\"coef_\", ascending=False)\n",
    "\n",
    "feature_importance_df\\\n",
    "    .head(10)\\\n",
    "    .round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "Let's compare our model to the baseline model (and to results in the literature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/baseline.pkl\", \"rb\") as f:\n",
    "    baseline_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the accuracy to compare to https://bradzzz.gitbooks.io/ga-dsi-seattle/content/dsi/dsi_05_classification_databases/2.1-lesson/assets/datasets/DefaultCreditCardClients_yeh_2009.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "y_baseline_pred = baseline_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred >= 0.5)\n",
    "baseline_acc = accuracy_score(y_test, y_baseline_pred >= 0.5)\n",
    "\n",
    "print(f\"Model accuracy: {round(100*acc, 2)}\")\n",
    "print(f\"Baseline model accuracy: {round(100*baseline_acc, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate this over a range of thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0, 1, 100)\n",
    "\n",
    "accuracies = [accuracy_score(y_test, y_pred >= _t) for _t in thresholds]\n",
    "baseline_accuracies = [accuracy_score(y_test, y_baseline_pred >= _t) for _t in thresholds]\n",
    "\n",
    "print(f\"Maximum model accuracy: {round(100*max(accuracies), 2)}\")\n",
    "print(f\"Maximum baseline model accuracy: {round(100*max(baseline_accuracies), 2)}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(thresholds, accuracies, label=\"RF\")\n",
    "ax.plot(thresholds, baseline_accuracies, label=\"Baseline\")\n",
    "ax.set(title=\"Accuracy by Threshold\", xlabel=\"Threshold\", ylabel=\"Accuracy\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall Operator Characteristic Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f\"Model ROC-AUC score: {round(100*roc_auc_score(y_test, y_pred), 2)}\")\n",
    "print(f\"Baseline model ROC-AUC score: {round(100*roc_auc_score(y_test, y_baseline_pred), 2)}\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "fpr_baseline, tpr_baseline, thresholds_baseline = roc_curve(y_test, y_baseline_pred)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr, label=\"RF\")\n",
    "ax.plot(fpr_baseline, tpr_baseline, label=\"Baseline\")\n",
    "ax.plot([0, 1], [0, 1], color=\"black\", linestyle=\"--\")\n",
    "ax.set(title=\"ROC Curve\", xlabel=\"FPR\", ylabel=\"TPR\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision/Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prec, rec, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "prec_baseline, rec_baseline, thresholds_baseline = precision_recall_curve(y_test, y_baseline_pred)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(prec, rec, label=\"RF\")\n",
    "ax.plot(prec_baseline, rec_baseline, label=\"Baseline\")\n",
    "ax.set(title=\"Precision-Recall Curve\", xlabel=\"Precision\", ylabel=\"Recall\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the same thing but with threshold explicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prec, rec, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "prec_baseline, rec_baseline, thresholds_baseline = precision_recall_curve(y_test, y_baseline_pred)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(thresholds, prec[:-1], color=kcs[0], label=\"RF-Precision\")\n",
    "ax.plot(thresholds, rec[:-1], color=kcs[1], label=\"RF-Recall\")\n",
    "ax.plot(thresholds_baseline, prec_baseline[:-1], color=kcs[0], linestyle=\"--\", label=\"Baseline-Precision\")\n",
    "ax.plot(thresholds_baseline, rec_baseline[:-1], color=kcs[1], linestyle=\"--\", label=\"Baseline-Recall\")\n",
    "ax.set(title=\"Precision-Recall Curve\", xlabel=\"Threshold\", ylabel=\"Score\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df.loc[X_test.index].copy()\n",
    "# get the residuals/squared deviance\n",
    "test_df[\"RESIDUALS\"] = -2*(y_test*np.log(y_pred) + (1 - y_test)*np.log(1 - y_pred))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(test_df[\"RESIDUALS\"], bins=np.arange(0, 1.01, 0.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"DEFAULT_PRED_PROBA\"] = y_pred\n",
    "test_df[\"BINNED_PRED_DEFAULT\"] = \\\n",
    "    np.array(pd.cut(test_df[\"DEFAULT_PRED_PROBA\"], np.arange(0, 1.01, 0.2), labels=range(1, 6)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "boxplot(x=\"BINNED_PRED_DEFAULT\", y=\"RESIDUALS\", data=test_df, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/random_forest.pkl\", \"wb\") as f:\n",
    "    pickle.dump(gs.best_estimator_, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with No Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"union__num_pipeline__feature_selector__attribute_names\": [\n",
    "        [\"LIMIT_BAL\", \"PAY_AMT6\", \"AGE\"] \n",
    "        + [f\"BILL_AMT_NORM{n}\" for n in range(1, 7)] \n",
    "        + [f\"PAY_AMT_NORM{n}\" for n in range(1, 6)],\n",
    "    ],\n",
    "    \"union__cat_pipeline__feature_selector__attribute_names\": [\n",
    "        [\"EDUCATION\", \"MARRIAGE\"] + [f\"PAY_{n}\" for n in range(1, 7)],\n",
    "    ],\n",
    "    \"classifier__n_estimators\": [200],\n",
    "    \"classifier__max_depth\": [10],\n",
    "    \"classifier__max_features\": [\"auto\"],\n",
    "    \"classifier__class_weight\": [\n",
    "        {0: 1, 1: 1.5},\n",
    "    ],\n",
    "}\n",
    "\n",
    "gs = create_random_forest_pipeline(X_train, y_train, param_grid)\n",
    "validation_auc = gs.best_score_\n",
    "test_auc = roc_auc_score(y_test, gs.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f\"Validation ROC-AUC score: {round(100*validation_auc, 2)}\")\n",
    "print(f\"Test ROC-AUC score: {round(100*test_auc, 2)}\\n\")\n",
    "pprint(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"union__num_pipeline__feature_selector__attribute_names\": [\n",
    "        [\"LIMIT_BAL\", \"PAY_AMT6\", \"AGE\"] \n",
    "        + [f\"BILL_AMT{n}\" for n in range(1, 7)] \n",
    "        + [f\"PAY_AMT{n}\" for n in range(1, 6)],\n",
    "    ],\n",
    "    \"union__cat_pipeline__feature_selector__attribute_names\": [\n",
    "        [\"EDUCATION\", \"MARRIAGE\"] + [f\"PAY_{n}\" for n in range(1, 7)],\n",
    "    ],\n",
    "    \"classifier__n_estimators\": [200],\n",
    "    \"classifier__max_depth\": [10],\n",
    "    \"classifier__max_features\": [\"auto\"],\n",
    "    \"classifier__class_weight\": [\n",
    "        {0: 1, 1: 1.5},\n",
    "    ],\n",
    "}\n",
    "\n",
    "gs = create_random_forest_pipeline(X_train, y_train, param_grid)\n",
    "validation_auc = gs.best_score_\n",
    "test_auc = roc_auc_score(y_test, gs.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f\"Validation ROC-AUC score: {round(100*validation_auc, 2)}\")\n",
    "print(f\"Test ROC-AUC score: {round(100*test_auc, 2)}\\n\")\n",
    "pprint(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "* Feature engineering important in improving model performance\n",
    "* Improve on baseline performance - incremental in terms of accuracy\n",
    "* Further investigations:\n",
    "    * Could do some sampling\n",
    "    * Remove unimportant features\n",
    "    * Merge redundant categories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surrey-workshop",
   "language": "python",
   "name": "surrey-workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
